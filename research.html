<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=GBK" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Research</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Home</div>
<div class="menu-item"><a href="index.html">Home</a></div>
<div class="menu-item"><a href="Bio.html">Biography</a></div>
<div class="menu-item"><a href="research.html">Research</a></div>
<div class="menu-category">Miscellaneous</div>
<div class="menu-item"><a href="Miscellaneous.html">Misc.</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Research</h1>
</div>
<h2>Papers and Preprints</h2>
<ol>
<li><p><a href="https://arxiv.org/pdf/2304.06767" target=&ldquo;blank&rdquo;>RAFT: Reward rAnked FineTuning for Generative Foundation Model Alignment</a> <br />
Hanze Dong*, Wei Xiong*,  Deepanshu Goyal, Rui Pan, Shizhe Diao, Jipeng Zhang, Kashun Shum and Tong Zhang, Preprint.<br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2211.01962" target=&ldquo;blank&rdquo;>GEC: A Unified Framework for Interactive Decision Making in MDP, POMDP, and Beyond</a> <a href="slideonlinegfa.pdf" onclick="javascript:urchinTracker('/downloads/slidegfarl.pdf');">[Slide] </a><br />
Han Zhong*, Wei Xiong*, Sirui Zheng, Liwei Wang, Zhaoran Wang, Zhuoran Yang and Tong Zhang, Preprint.<br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org" target=&ldquo;blank&rdquo;>Reward Teaching for Federated Multi-Armed Bandits</a><br />
Chengshuai Shi, Wei Xiong, Cong Shen, and Jing Yang, IEEE International Symposium on Information Theory (ISIT 2023)<br /><br /></p>
</li>
<li><p><a href="https://arxiv.org" target=&ldquo;blank&rdquo;>Provably Efficient Offline Reinforcement Learning with Perturbed Data Sources</a><br />
Chengshuai Shi, Wei Xiong, Cong Shen, and Jing Yang, <i>ICML</i> 2023.<br /><br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2212.05949" target=&ldquo;blank&rdquo;>Corruption-Robust Algorithms with Uncertainty Weighting for Nonlinear Contextual Bandits and Markov Decision Processes</a> <br />
Chenlu Ye, Wei Xiong, Quanquan Gu and Tong Zhang, <i>ICML</i> 2023.<br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2205.15512" target=&ldquo;blank&rdquo;>Nearly Minimax Optimal Offline Reinforcement Learning with Linear Function Approximation: Single-Agent MDP and Markov Game</a> <a href="slideoffline.pdf" onclick="javascript:urchinTracker('/downloads/slidegfarl.pdf');">[Slide] </a><br />
Wei Xiong*, Han Zhong*, Chengshuai Shi, Cong Shen, Liwei Wang, and Tong Zhang,  <i>ICLR</i> 2023. <br /><br /></p>
</li>
<li><p><a href="https://proceedings.mlr.press/v162/xiong22b/xiong22b.pdf" target=&ldquo;blank&rdquo;>A Self-Play Posterior Sampling Algorithm for Zero-Sum Markov Game</a> <br />
Wei Xiong, Han Zhong, Chengshuai Shi, Cong Shen, and Tong Zhang, <i>ICML</i> 2022.<br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2202.07511" target=&ldquo;blank&rdquo;>Pessimistic Minimax Value Iteration: Provably Efficient Equilibrium Learning from Offline Datasets</a> <br />
Han Zhong*, Wei Xiong*, Jiyuan Tan*, Liwei Wang, Tong Zhang, Zhaoran Wang, and Zhuoran Yang, <i>ICML</i> 2022. <br /><br /></p>
</li>
<li><p><a href="note_stability.pdf" onclick="javascript:urchinTracker('/downloads/cv.pdf');">An Alternative Analysis of High-Probability Generalization Bound for Uniformly Stable Algorithms</a><br />
Wei Xiong, Yong Lin, and Tong Zhang, Project Report, Not intended for publication.<br /><br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2012.15010" target=&ldquo;blank&rdquo;>PMGT-VR: A decentralized proximal-gradient algorithmic framework with variance reduction</a>  <a href="slideopt.pdf" onclick="javascript:urchinTracker('/downloads/slide<u>gfa</u>rl.pdf');">[Slide] </a><br /> 
Haishan Ye*, Wei Xiong*, and Tong Zhang,  Under Minor Revision at <i>TPAMI</i>. <br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2110.14622" target=&ldquo;blank&rdquo;>Heterogeneous Multi-player Multi-armed Bandits: Closing the Gap and Generalization</a>  [<a href="https://github.com/ShenGroup/MPMAB_BEACON" target=&ldquo;blank&rdquo;>Code</a>] <br /> 
Chengshuai Shi, Wei Xiong, Cong Shen, and Jing Yang, <i>NeurIPS</i>, 2021.<br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2110.14628" target=&ldquo;blank&rdquo;>(Almost) Free Incentivized Exploration from Decentralized Learning Agents</a>  [<a href="https://github.com/ShenGroup/Observe_then_Incentivize" target=&ldquo;blank&rdquo;>Code</a>] <br /> 
Chengshuai Shi, Haifeng Xu, Wei Xiong, and Cong Shen, <i>NeurIPS</i>, 2021.<br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2110.13578" target=&ldquo;blank&rdquo;>Distributional Reinforcement Learning for Multi-Dimensional Reward Functions</a>  <br /> 
Pushi  Zhang,  Xiaoyu  Chen,  Li  Zhao,  Wei  Xiong,  Tao  Qin,  and  Tie-Yan  Liu, <i>NeurIPS</i>, 2021.<br /> <br /></p>
</li>
<li><p><a href="https://arxiv.org/abs/2003.00162" target=&ldquo;blank&rdquo;>Decentralized multi-player multi-armed bandits with no collision information</a>  [<a href="https://github.com/WeiXiongUST/multi_player_multi_armed_bandit_algorithms" target=&ldquo;blank&rdquo;>Code*</a>] <br /> 
Chengshuai Shi, Wei Xiong, Cong Shen, and Jing Yang, <i>AISTATS</i>, 2020.<br /> <br /></p>
</li>
</ol>
<p>(* equal contribution or alphabetical order)</p>
<p>The Code* implementes many SOTA and baseline MPMAB algorithms, which is a nice work of Cindy Trinh.</p>
</td>
</tr>
</table>
</body>
</html>
